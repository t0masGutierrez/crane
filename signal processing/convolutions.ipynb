{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X9Mx7QF7BxIn"
   },
   "source": [
    "# **Convolutions: A fancy multiplication algorithm with many uses**\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "##### *by [Hannah Hasson](https://hrhasson.github.io/) (Sandia National Labs)*\n",
    "\n",
    "Reminder: [Code of Conduct](https://docs.google.com/presentation/d/1UiBbQLGCZ_8VTTufJGitjnfz2Lj12TzAPuvHLvRLMhk/edit?usp=sharing)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "A *highly* recommended video to accompany this lesson : https://www.youtube.com/watch?v=KuXjwB4LzSA\n",
    "\n",
    "Much of this lesson is based on this excellent guide: https://betterexplained.com/articles/intuitive-convolution/\n",
    "&nbsp;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vIZ4NO1A6pMM"
   },
   "source": [
    "#**What is a convolution?**\n",
    "\n",
    "A convolution can be thought of as a fancier way to multiply two functions, and is sometimes referred to as \"blending\" two curves. This is a more complex algorithm, though: there is an integral involved! Let's say we want to convolve two 1D curves, $f(t)$ and $g(t)$. The convolution $(f \\ast g)$ is:\n",
    "\n",
    "$$(f \\ast g)(t):=\\int_{-\\infty}^{\\infty} f(\\tau) g(t-\\tau) d \\tau$$\n",
    "\n",
    "**Note that in math, convolutions are always denoted with the star $\\ast$.** Let's break down more simply what is happening though, because this looks gross:\n",
    "\n",
    "1. Take two curves (f and g)\n",
    "2. Flip one backwards (hence the $-\\tau$)\n",
    "3. Displace the backwards curve from the other by some constant $t$\n",
    "4. Get the area under the curves where they overlap\n",
    "5. Rinse and repeat for different shifts ($t$ values)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "You can think of this as the **Missy Elliot algorithm: put your thing down, flip it and reverse it.**\n",
    "\n",
    "This means you \"slide\" one curve along the other and add up the area to get the new value at each shift $t$. This becomes much more concrete once you look at how to do it with discrete data. Now we will assume that **each of our curves $f$ and $g$ are a 1D array of values**. For simplicity let's start by assuming curve $g$, which we call the **kernel** (the one we slide, usually the smaller one), is only one element. Here is a visual of what that process looks like:\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1UhXchrI42Cmu31BuiZcp3S4IzqiLBYrO\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "Each time the kernel slides, we multiply it by the cell it is lined up with to get the new value at that point. You may have noticed this is just equivalent to multiplying the top array by the value in the kernel. This is true, but becomes more interesting once we make the kernel longer than one element. Let's try this now with a kernel that is 2 elements long:\n",
    "\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"500\" src=\"https://drive.google.com/uc?export=view&id=1yFVrR2yGjB-_kl2bUGjWOLlFNoOGojnA\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "Now we multiply each element in the kernel with the values of the elements they line up with, THEN add those products together. This now gives a completely different array as the output. But when does this even come up in research?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eQxq2aWL1OZ3"
   },
   "source": [
    "##**Where do convolutions show up in science?**\n",
    "\n",
    "When you google a convolution these days, you will mostly find people talking about **machine learning and convolutional neural networks (CNNs)**. While this is an important application of convolutions, they also show up in a lot of situations you may not expect. For example, calculating the total medicine needed each day as new patients come into a clinic may be represented with a convolution ([see explanation here](https://betterexplained.com/articles/intuitive-convolution/#Part_1_Hospital_Analogy)). This can be generalized to anything with competing rates of change, such as buildup of radioactive nuclear waste in a power plant where the waste present is always decaying but new waste is also being introduced at the same time.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Convolutions are a critical tool in all types of signal/image processing. You can create kernels that detect edges in images, smooth noisy data, and fix optical distortion in a recorded image (including telecopes, microscopes, and spectrometers).\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "What this means is that convolutions are useful processing tools, but also that **a lot of measurements we make in real life are actually the true signal convolved with distortions of the instrument we used to measure.** If you can characterize what an instrument's response function is (i.e. the way it blurs/distorts sharp edges), then you can remove its effects using a **deconvolution**. This means you can un-blur your data/images in these cases!\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Here are two examples of deconvolving signals to get a much sharper measurement:\n",
    "\n",
    "* 1D example of a measured signal (green) and the deconvolved signal (blue) based on the instrument. The peaks become much sharper and more obvious once the signal is deconvolved:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://terpconnect.umd.edu/~toh/spectrum/Deconvolution.html\">\n",
    "  <img width=\"800\" src=\"https://drive.google.com/uc?export=view&id=1UZVpseVWhNrRRwqEXukbsvHhQxId9Zdc\">\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "* An image of the Antenna galaxies before (a) and after (b) deconvolution with a gaussian kernel from the telescope and camera optics:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://www.researchgate.net/figure/Space-image-deconvolution-results-Source-ESA-Hubble-distributed-under-CC-BY-40_fig1_341830887\">\n",
    "  <img width=\"500\" src=\"https://www.researchgate.net/publication/341830887/figure/fig1/AS:898026855993356@1591117695781/Space-image-deconvolution-results-Source-ESA-Hubble-distributed-under-CC-BY-40.jpg\">\n",
    "  </a>\n",
    "</p>\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Another crucial application of convolutions comes into play whenever you're dealing with filtering with **Fourier transforms**! What's that, you thought you had escaped them? Nope, they're everywhere! We'll get further into that later in the lesson, but **applying filters in fourier space inherently involves convolutions**! So you've been doing them all along! Mwahaha!\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <a href=\"https://www.researchgate.net/figure/Space-image-deconvolution-results-Source-ESA-Hubble-distributed-under-CC-BY-40_fig1_341830887\">\n",
    "  <img width=\"300\" src=\"https://i.pinimg.com/originals/ea/60/c9/ea60c9377cdc5403c901336afac737c3.jpg\">\n",
    "  </a>\n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RAcIV81Asre"
   },
   "source": [
    "#**How to perform a 1D convolution in python**\n",
    "\n",
    "Let's learn how to do convolutions ourselves. Thankfully python makes it very straightforward to perform this operation. You don't need to write some big crazy `for` loop that shifts one array past your other array and takes the product. All you need to do is throw your two arrays into the function [numpy.convolve()](https://numpy.org/doc/stable/reference/generated/numpy.convolve.html)\n",
    "\n",
    "    np.convolve(array1, array2, mode=\"full\")\n",
    "\n",
    "The lovely thing about convolutions is that they are commutative operations, meaning **it doesn't matter what order you put the arrays in**. So you can put the kernel and the input in whichever order you want.\n",
    "\n",
    "The mode determines whether the convolution will only count regions where all the cells of the kernel overlap with the input array (\"valid\" mode) or will count regions where only some cells overlap at the edges (\"full\" mode). You can also just ask it to make the returned array the same size as the largest of the inputs (\"same\" mode)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4vPJL_i2FwpZ"
   },
   "source": [
    "###**Exercise 1:**\n",
    "Make a 50-element 1D array using `np.linspace()` that goes from -2$\\pi$ to 2$\\pi$ and then make another array that feeds these points into a sine function. Make a kernel array with 3 values that are all the same. Convolve the kernel with the sine array in \"same\" mode. Plot the input arrays and the result together on one plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1746299070871,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "JV76hTeIE6UY",
    "outputId": "17c1c9f3-f43b-4d45-8ba5-e6a46c5a24d3"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#code here\n",
    "x = np.linspace(-2*np.pi, 2*np.pi, 50)\n",
    "sinx = np.sin(x)\n",
    "kern = 3 * np.ones(3)\n",
    "conv = np.convolve(sinx, kern, mode=\"same\")\n",
    "plt.plot(sinx, label=\"sin(x)\")\n",
    "plt.plot(kern, label = \"kernel\")\n",
    "plt.plot(conv, label=\"convolution\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wGWhRNIL4Hq_"
   },
   "source": [
    "#**Applying convolutions: Smoothing data**\n",
    "This is where we start exploring the research applications we discussed! Convolutions are extremely powerful and can do a lot of different kinds of operations. Let's start by discussing how you can smooth data with convolutions.\n",
    "\n",
    "<br>\n",
    "\n",
    "##Uniform Moving Averages\n",
    "\n",
    "One of the simplest applications of a convolution can be to compute a **moving average** (also called a rolling average) over a particular number of cells. This takes the mean of several adjacent cells and makes it the new value of the cell aligned with the center of the kernel. This is a great way to smooth data! We could take a moving average across two cells by just taking the two-element kernel in the GIF earlier and making each element's value 0.5. That way it takes an average of the two cells that the kernel is lined up with.\n",
    "\n",
    "If you wanted to do a moving average over 3 cells, you'd simply use a kernel with 3 elements where all the values are 1/3. The pattern here is for a kernel of length **n**, the value of all the cells should be **1/n**.\n",
    "\n",
    "Here is a nice image of a moving average (in red) of some really noisey data (in blue):\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"400\" src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/6/6d/Lissage_sinus_bruite_moyenne_glissante.svg/800px-Lissage_sinus_bruite_moyenne_glissante.svg.png\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "Choosing a longer kernel will mean you are averaging over more points, and therefore your data will become smoother! However, you don't want it so smoothed that you lose the overall shape of your data. So it's important to pick your kernel size carefully.\n",
    "\n",
    "<br>\n",
    "\n",
    "##Weighted averages: Gaussian smoothing\n",
    "\n",
    "You can also do weighted averages this same way, so that (for example) values in cells that are closer to the center of the kernel influence the new value the most. Again here we will make the values in the kernal add up to 1 (this is called normalizing). One extremely common example of a weighted, normalized kernel is the **Gaussian kernel**. This is where you pick a kernel of a certain length, then assign the values following the shape of a Gaussian curve.\n",
    "\n",
    "For example, if you wanted a kernel with a length of 15, your element values would look something like this:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"400\" src=\"https://mathworld.wolfram.com/images/eps-svg/BinomialGaussian_1000.svg\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "\n",
    "This works well in 2D too! You would have a large 2D input array $f$ and a small 2D Gaussian kernel $g$ that would appear something like this:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"250\" height=\"300\" src=\"https://www.researchgate.net/profile/Giovanna-Sannino/publication/302973724/figure/fig3/AS:651916656791555@1532440451926/2D-Gaussian-filter.png\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "Where the red values are higher and the blue values are closer to zero. The sum of all the kernel cells must still add to 1.\n",
    "\n",
    "\n",
    "Let's do an example of a moving average and a gaussian smoothing filter now!\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwPIhFxkUNG8"
   },
   "source": [
    "### **Exercise 2: 1D smoothing**\n",
    "\n",
    "#### Part A)\n",
    "Let's first make a set of noisy 1D data. We have imported the `random` package as `r` and then make a set of 300 random numbers between 0 and 20 using `rand`. It is up to you to now make a uniform array to be our moving average kernel. Use `np.ones` to make an array of some length *n* and then multiply it by *1/n to normalize it. Apply the convolution to the data using `np.convolve` and then plot it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 256,
     "status": "ok",
     "timestamp": 1746299071126,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "1434HLpaTrTa",
    "outputId": "aa90fd43-13cc-485d-f18d-59cbbe77a31a"
   },
   "outputs": [],
   "source": [
    "import numpy.random as r\n",
    "\n",
    "data = 20*r.rand(300)\n",
    "\n",
    "#code here\n",
    "n = 100\n",
    "kern = (1/n) * np.ones(n)\n",
    "conv = np.convolve(data, kern, mode=\"same\")\n",
    "plt.plot(data,label=\"data\")\n",
    "plt.plot(conv,label=\"smooth data\", color=\"orange\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-6v1S7jXbmgF"
   },
   "source": [
    "Play around with different kernel lengths to see what it does to the data! Don't forget to change your normalization factor each time (*1/n* for array length *n*)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EKv57DUFYxdB"
   },
   "source": [
    "#### Part B)\n",
    "\n",
    "Now let's do a 1D convolution with a gaussian kernel. First we will upload a data file, \"spectrum.csv\" which we used briefly in Part 1. Read its two columns into arrays using `np.genfromtxt`. Once loaded, check the shape of the array (`np.shape`) and plot the second column (flux) against the first column (wavelength).\n",
    "\n",
    "\n",
    "To make our 1D gaussian kernel, we will use the provided `gaussian_kernel_1D` function, whose inputs are:\n",
    "* n, the number of points (choose an odd number so we have a peak at the center)\n",
    "* sigma, half the width of the Gaussian curve\n",
    "\n",
    "Make a gaussian kernel that is 11 points long with sigma=2 and then convolve it with the signal column of your spectrum data in \"same\" mode. Plot the resulting array against the wavelength.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 445
    },
    "executionInfo": {
     "elapsed": 130,
     "status": "ok",
     "timestamp": 1746299071255,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "pq0jTownw9Pn",
    "outputId": "12a19a82-2236-4bff-c159-c2a95b62d55b"
   },
   "outputs": [],
   "source": [
    "def gaussian_kernel_1D(n,sigma):\n",
    "    r = np.linspace(-int(n/2)+0.5,int(n/2)-0.5, n)\n",
    "    return [1 / (sigma * np.sqrt(2*np.pi)) * np.exp(-float(x)**2/(2*sigma**2)) for x in r]\n",
    "\n",
    "#code here\n",
    "wavelength, flux = np.genfromtxt(\"spectrum.csv\", delimiter=\",\", unpack=True)\n",
    "\n",
    "kern = gaussian_kernel_1D(21, 1)\n",
    "convFlux = np.convolve(kern, flux, mode=\"same\")\n",
    "plt.plot(wavelength, flux, label=\"flux\")\n",
    "plt.plot(wavelength, convFlux, label=\"gaussian flux\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1sjpYd17qPLG"
   },
   "source": [
    "Note that this causes the peak to shrink, but also to widen (area under the curve is preserved because the kernel adds to 1). Once you get your plot, try playing around with the size of your kernel and the width of the gaussian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZJwMkpySgFsj"
   },
   "source": [
    "&nbsp;\n",
    "\n",
    "---\n",
    "#TAKE A BREAK HERE\n",
    "---\n",
    "\n",
    "&nbsp;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28npZMWkgSGJ"
   },
   "source": [
    "#**2D convolutions**\n",
    "\n",
    "It may still not be clear how you would even perform a 2D convolution. Let's look at a handy-dandy graphic!\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"500\" src=\"https://www.practiceprobs.com/problemsets/python-numpy/images/convolution.gif\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "Note that the values in the kernel in this graphic are chosen randomly and do not add up to 1.\n",
    "\n",
    "\n",
    "We can see that each time we move the kernel around we multiply all the overlapping values and then add them to get one value in the output array. That output array is smaller than the original one we started with, though... Why?\n",
    "That is because this GIF is doing the 2D equivalent of \"valid\" mode from `numpy.convolve` where it only outputs values when **the entire kernel is overlapping with the input array**.\n",
    "\n",
    "If we want the output array to be the same size as the input array, we need to calculate elements where the center of the kernel overlaps with the edge values too. This means there will be elements of the kernel that don't overlap with anything... What do we do? There are different ways to handle this, but a common approach is to just add a layer of cells around the edge of the input array with the same value as the current boundary cells.\n",
    "\n",
    "#Edge detection in images\n",
    "\n",
    "Often in research we have images of our experiment at multiple times, and we would like to track how some feature evolves. This is when edge detection can be extremely useful. For example, here is a cell mutating and growing where the egde is being tracked over time:\n",
    "\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"250\" height=\"300\" src=\"https://cbia.fi.muni.cz/images/research/spatiotemporal/organoids/cropped-results-FIB.gif\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "\n",
    "\n",
    "As with smoothing, there are a few different types of kernels that you can use to do edge detection with convolutions. All of these are essentially different ways to **represent a derivative as a matrix**. This makes sense because if we took the derivative at every pixel in an image, the largest derivatives would occur at the sharpest edges where the pixel values jump the most.\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "We will use one of the simplest methods here, the **Laplacian kernel**. Here is what that looks like in a 3x3 array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1,
     "status": "ok",
     "timestamp": 1746299071256,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "GSw9XQ8ScBzv"
   },
   "outputs": [],
   "source": [
    "laplacian_kernel = np.array([[-1, -1, -1],\n",
    "                             [-1,  8, -1],\n",
    "                             [-1, -1, -1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d94LDDZWl4jw"
   },
   "source": [
    "Let's now try colvolving this with an image. To do that, we will use the function **`cv2.filter2d`** which has the following form:\n",
    "\n",
    "```\n",
    "cv2.filter2d(image, depth, kernel)\n",
    "```\n",
    "\n",
    "The *image* will be the 2D array of our image. *Depth* is the data type of the output array (i.e. different sized floats), but **we will always set depth to -1** to use the same data type as our input. Finally *kernel* will of course be our 2D kernel array.\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Let's try this out now. We will load in an image I arbitrarily chose from the interwebs and apply the edge detection filter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 850
    },
    "executionInfo": {
     "elapsed": 564,
     "status": "ok",
     "timestamp": 1746299071820,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "MxuZhjdhl3pS",
    "outputId": "2b14fed4-b2ca-4ac6-b73f-ecc157672b10"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "#Handy Colab trick to pull images from the internet\n",
    "!wget https://upload.wikimedia.org/wikipedia/en/4/45/Side_Eyeing_Chloe.jpg -O /content/side_eye.png\n",
    "\n",
    "#Load image and display\n",
    "input_image = cv2.imread(\"side_eye.png\",0) #read in greyscale image\n",
    "\n",
    "plt.imshow(input_image,cmap=\"grey\") #display image\n",
    "plt.axis(\"Off\") #remove the axes\n",
    "plt.title(\"Original\")\n",
    "plt.show()\n",
    "\n",
    "#Filter image and display\n",
    "filtered_image = cv2.filter2D(input_image, -1, laplacian_kernel) #apply the edge detection filter\n",
    "\n",
    "plt.imshow(filtered_image,cmap=\"grey\") #display filtered image\n",
    "plt.axis(\"Off\") #remove the axes\n",
    "plt.title(\"Edge Detection Filtered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HZMfnWdTlGDx"
   },
   "source": [
    "Nice! We see that all of the sharp edges are displayed in white (high pixel value) while everything else is left in black (zero pixel value). However, this filter is very sensitive to noise.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "It may sound strange, but often this process is enhanced by **first performing a Gaussian blur on your data and THEN applying the Laplacian**. This is commonly referred to as an \"LoG\" filter, which stands for \"**Laplacian of Gaussian**.\" Let's try that now.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVtQ8iO4pZWP"
   },
   "source": [
    "###**Exercise 3**\n",
    "\n",
    "Use cv2.filter2D with a Gaussian kernel to apply a Gaussian blur to our image from the last example, and then again with a Laplacian kernel to apply edge detection.\n",
    "\n",
    "####Part A)\n",
    "First apply a Gaussian filter using the following kernel:\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"250\" src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/f91401a3e97428f14862afa1c781c55f4157580b\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "Then display your blurred image using `plt.imshow`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 154,
     "status": "ok",
     "timestamp": 1746299273506,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "BSOWjNj_i83R",
    "outputId": "ecc1fbba-f0a6-40b2-b8e4-7804dede9b67"
   },
   "outputs": [],
   "source": [
    "#code here\n",
    "gaussKern = (1/256) * np.array([[1, 4, 6, 4, 1,], [4, 16, 24, 16, 4], [6, 24, 36, 24, 6], [4, 16, 24, 16, 4], [1, 4, 6, 4, 1,]])\n",
    "gaussImage = cv2.filter2D(input_image, -1, gaussKern)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"gaussian image\")\n",
    "plt.imshow(gaussImage, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iQeGUNlqtAaY"
   },
   "source": [
    "For future reference, there is also a built-in function in scipy.ndimage called [`gaussian_filter`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter.html) that can also make your gaussian kernel of any size and colvolve it with your 2D image array. The same exists for applying gaussian blur to a 1D array called [`gaussian_filter_1D`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.ndimage.gaussian_filter1d.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rI2BiP1qrTI8"
   },
   "source": [
    "####Part B\n",
    "\n",
    "Now apply Laplacian edge detection on the blurred image from above using the same kernel as we did in the example. Display your final blurred and edge detected image!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1746299286649,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "BzM1z2ENrRst",
    "outputId": "d58ae774-7a52-40a7-b9c5-0593bb3e3bbd"
   },
   "outputs": [],
   "source": [
    "#code here\n",
    "laplaceImage = cv2.filter2D(gaussImage, -1, laplacian_kernel)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"laplacian of gaussian image\")\n",
    "plt.imshow(laplaceImage, cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338
    },
    "executionInfo": {
     "elapsed": 176,
     "status": "ok",
     "timestamp": 1746299290542,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "FYiPhXSWtcmp",
    "outputId": "10e00098-66a4-44a8-fafe-82565b4b874b"
   },
   "outputs": [],
   "source": [
    "#Compare to the original Laplacian filter by itself (run this cell as is)\n",
    "plt.imshow(filtered_image,cmap=\"grey\") #display filtered image\n",
    "plt.axis(\"Off\") #remove the axes\n",
    "plt.title(\"Edge Detection Filtered\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wY4lzDv5tWxd"
   },
   "source": [
    "You will notice that all the edges are much more muted in our smoothed and edge filtered version. This can be a good thing for supressing high-signal noise that can falsely show up as edges, or for removing already weak edges that we want to ignore.\n",
    "\n",
    "If you are looking for a feature's boundary, it's generally a good idea to smooth first so that the boundary you detect will be smooth.\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "There are also other types of edge detection kernels that will pick out edges only along one direction, or find more subtle edges. Check out [this article](https://medium.com/@akashsingh9303/image-processing-using-convolution-kernels-in-python-a-practical-guide-2da3252b033a) for some examples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PTzp_ty4u9VX"
   },
   "source": [
    "#**The link between convolutions and Fourier transforms**\n",
    "\n",
    "So we've been subtly leading you toward a piece of information that is mathematically extremely useful. There is an important tie between convolutions and Fourier transforms:\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "**Taking a convolution of two functions (or arrays) is equivalent to multiplying them in Fourier/frequency space**\n",
    "\n",
    "This is called the **Convolution Theorem**!\n",
    "\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "...What? This is a weird statement, so let's look at it in practice. If I take the Fourier transforms of my image and my 2D edge detection filter as so:\n",
    "\n",
    "* first we pad our kernel array with zeros until it is the same size as the image array. That way we can later multiply the two arrays element-wise\n",
    "* then take the Fourier transform of each array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 829
    },
    "executionInfo": {
     "elapsed": 445,
     "status": "ok",
     "timestamp": 1746299072642,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "i6iQmqW2tSQP",
    "outputId": "5704f713-e78b-4686-8d65-2277049e37bf"
   },
   "outputs": [],
   "source": [
    "#pad the kernel array with zeros until it's the same size as the image array\n",
    "rowpad= int((input_image.shape[0]-laplacian_kernel.shape[0])/2) #how many rows of zeros needed\n",
    "colpad = int((input_image.shape[1]-laplacian_kernel.shape[1])/2) #how many columns of zeros needed\n",
    "\n",
    "kernel_pad = np.pad(laplacian_kernel,((rowpad,rowpad),(colpad,colpad)),mode=\"constant\")\n",
    "kernel_pad = np.fft.ifftshift(kernel_pad) #shift the kernel so the FFT works\n",
    "\n",
    "print(kernel_pad)\n",
    "\n",
    "#Take Fourier transforms of image and kernel\n",
    "FTimage = np.fft.fft2(input_image)\n",
    "FTkernel = np.fft.fft2(kernel_pad)\n",
    "\n",
    "plt.imshow(np.log10(np.abs(FTimage)),cmap=\"grey\")\n",
    "plt.title(\"Image Fourier transform\")\n",
    "plt.show()\n",
    "plt.imshow(np.log10(np.abs(FTkernel)),cmap=\"grey\")\n",
    "plt.title(\"Kernel Fourier transform\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q_45Os_AzZZs"
   },
   "source": [
    "Ok, well this doesn't tell us much yet. Let's multiply these and then do the inverse FFT to see what we have back in the spatial domain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 316
    },
    "executionInfo": {
     "elapsed": 140,
     "status": "ok",
     "timestamp": 1746299523095,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "bz-Kx6w5yu0n",
    "outputId": "429b6168-9d5f-4f5f-b565-8c3092d1a355"
   },
   "outputs": [],
   "source": [
    "FTconv = FTimage*np.conj(FTkernel) #conjugate means flip sign of imaginary numbers\n",
    "\n",
    "convolved_image = np.fft.ifft2(FTconv)\n",
    "plt.axis(\"Off\") #remove the axes\n",
    "plt.imshow(np.real(convolved_image),cmap=\"grey\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OiaIhlNvGiCZ"
   },
   "source": [
    "It's not perfect (there is a decent amount of noise introduced here). But it did achieve convolving our image with our edge detector! This means that you can actually achieve convolutions with Fourier transforms! In fact, this is a computationally quicker way to do them for large arrays, so people will often use [`scipy.signal.fftconvolve`](https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.fftconvolve.html).\n",
    "\n",
    "The syntax for that function is\n",
    "\n",
    "```\n",
    "scipy.signal.fftconvolve(array1, array2)\n",
    "\n",
    "```\n",
    "\n",
    "Where one of the arrays is your data and one is the kernel.\n",
    "\n",
    "\n",
    "As a final exercise, let's try using this method to convolve our example image and our edge detection kernel. Again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 1065,
     "status": "ok",
     "timestamp": 1746299073999,
     "user": {
      "displayName": "Tomas",
      "userId": "09314415480168799529"
     },
     "user_tz": 300
    },
    "id": "TA5nCCnC_DH3",
    "outputId": "c4a0df8e-9bb6-4f70-edc5-8c5b3dcba93e"
   },
   "outputs": [],
   "source": [
    "import scipy.signal as sig\n",
    "\n",
    "fftconv = sig.fftconvolve(input_image,laplacian_kernel)\n",
    "\n",
    "plt.imshow(fftconv,cmap=\"grey\")\n",
    "plt.axis(\"Off\") #remove the axes\n",
    "plt.title(\"Edge Detection with FFT\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SqWcrGmaJ52r"
   },
   "source": [
    "Again, there was noise introduced that made our contrast not quite as sharp, but the convolution was achieved!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l5T6LBa0ckv9"
   },
   "source": [
    "##Deconvolutions\n",
    "\n",
    "So knowing this now, let's think about how you would *deconvolve* an image. Let's say that our true data is array **f**, our instrument's blurring kernel is **g** and our convolved data we measure is **h**. In theory, we could get the true data **f** via Fourier transforms (FT):\n",
    "\n",
    "We know\n",
    "\n",
    "(**f** * **g**) = **h**\n",
    "\n",
    "and with the Convolution theorem we can then express:\n",
    "\n",
    "FT(**f**) $\\cdot$ FT(**g**) = FT(**h**)\n",
    "\n",
    "we can then do a straightforward division:\n",
    "\n",
    "FT(**f**) = FT(**h**)/FT(**g**)\n",
    "\n",
    "Now all we do is take the inverse FT of both sides and shazam! We have our true signal **f**!\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "Note that the noise produced from this technique can be very problematic if you compute it this way. However, if you can characterize the noise that exists in your data to begin with, there are methods that can be used to reduce the noise amplification in deconvolution.\n",
    "\n",
    "That is how you end up with the cool astronomy image example we gave in the beginning!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VC7M95p9Kzjw"
   },
   "source": [
    "#**Outro**\n",
    "\n",
    "Great job today! Missy Elliott is proud of you for putting your thing down, flipping and reversing it!\n",
    "\n",
    "<p align=\"center\">\n",
    "  <img width=\"400\" src=\"https://i.makeagif.com/media/7-01-2016/tptOQ_.gif\"\n",
    ">\n",
    "</p>\n",
    "\n",
    "\n",
    "If you are still not convinced that convolutions are interesting/useful, let me finish with a helpful list of things that ChatGPT suggested that convolutions are used for (this is of course not a comprehensive list:)\n",
    "\n",
    "&nbsp;\n",
    "\n",
    "1. **Image Processing and Computer Vision**\n",
    "* Edge Detection\n",
    "* Blurring and Sharpening\n",
    "* Feature Extraction\n",
    "2. **Signal Processing**\n",
    "* Noise Reduction\n",
    "* Echo Cancellation\n",
    "* Time-Domain Filtering\n",
    "3. **Medical Imaging**\n",
    "* Reconstructing MRI and CT images\n",
    "* Image Enhancement\n",
    "* Feature Detection of tumors, fractures, or abnormalities\n",
    "4. **Astronomy**\n",
    "* Image De-noising for ground-based telescopes\n",
    "* Pattern Recognition of celestial objects in large datasets\n",
    "* Signal Analysis for radio telescopes\n",
    "5. **Audio Processing**\n",
    "* Applying Reverb and Echo Effects\n",
    "* Speech Recognition\n",
    "* Sound Localization (surround sound)\n",
    "6. **Physics and Engineering**\n",
    "* Wave Propagation through different media\n",
    "* Correction of signal distortion\n",
    "* Finite Element Analysis (solving partial differential equations)\n",
    "7. **Neuroscience**\n",
    "* Brain Signal Analysis (EEG and fMRI)\n",
    "* Neural Modeling\n",
    "8. **Natural Language Processing (NLP)**\n",
    "* Text Classification\n",
    "* Language Translation\n",
    "9. **Geophysics**\n",
    "* Seismic Data Analysis\n",
    "* Reconstructing Subsurface Images\n",
    "10. **Robotics**\n",
    "* Sensor Data Processing (navigation and obstacle detection)\n",
    "* Object Recognition\n",
    "11. **Quantum Mechanics**\n",
    "* Wave Function Analysis\n",
    "12. **Environmental Science**\n",
    "* Climate Modeling\n",
    "* Satellite Image Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nl6IcOVNUKN"
   },
   "source": [
    "Thanks for attending the Signal and Image Processing track! We would love to get your thoughts on the track in the [feedback form](https://docs.google.com/forms/d/e/1FAIpQLSdzzC9-vBv5DflUQ2kgp4Z_6JKkvi_Id2D3lTLezRikHDJkww/viewform)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "tomas",
   "language": "python",
   "name": "tomas"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
